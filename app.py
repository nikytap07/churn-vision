import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from eda import run_eda
from preprocess import preprocess_data
from model import train_and_save_model, visualize_model, load_model_and_scaler, run_prediction
import os
from clustering import run_clustering, plot_churn_by_cluster, plot_categorical_distributions, run_hierarchical_clustering

from preprocess import get_feature_groups
import os
from sklearn.metrics import confusion_matrix

st.set_page_config(
    page_title='ChurnVision App',
    layout='wide',
    initial_sidebar_state='expanded'
)

st.title("ChurnVision: EDA, –û–±—É—á–µ–Ω–∏–µ –∏ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

tab1, tab2, tab3 = st.tabs(["\U0001F4CA –ê–Ω–∞–ª–∏–∑ –∏ –æ–±—É—á–µ–Ω–∏–µ", "\U0001F52E –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", "\U0001F465 –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"])

# ---------- TAB 1: EDA –∏ –æ–±—É—á–µ–Ω–∏–µ ----------
with tab1:
    st.subheader("\U0001F4C1 –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–µ–≥–æ —Ñ–∞–π–ª–∞")
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª", type=["csv", "xlsx"], key="train")

    do_eda = st.sidebar.checkbox("–í—ã–ø–æ–ª–Ω–∏—Ç—å EDA", value=True)

    eda_options = st.sidebar.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ, –∫–∞–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å:",
        [
            "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
            "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
            "QQ-–≥—Ä–∞—Ñ–∏–∫–∏",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ churn",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ churn",
            "PHIK –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è",
            "–í–∑–∞–∏–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (MI)"
        ],
        default=[
            "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
            "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
            "QQ-–≥—Ä–∞—Ñ–∏–∫–∏",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ churn"
        ]
    )

    selected_model = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
        ["Logistic Regression (balanced)", "Logistic Regression (default)", "Random Forest", "XGBoost"]
    )

    if "all_model_metrics" not in st.session_state:
        st.session_state.all_model_metrics = {}

    if uploaded:
        df = pd.read_csv(uploaded) if uploaded.name.endswith(".csv") else pd.read_excel(uploaded)
        df.columns = df.columns.str.lower().str.strip()

        if 'churn' not in df.columns:
            st.error("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É 'churn'. EDA –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.")
            if do_eda:
                st.header("Exploratory Data Analysis (EDA) \U0001F50D")
                run_eda(df, eda_options)
        else:
            X_train, X_test, y_train, y_test = preprocess_data(df, target_column='churn')

            st.success("\u2705 –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            st.write("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å X_train:", X_train.shape)

            if do_eda:
                st.header("Exploratory Data Analysis (EDA) \U0001F50D")
                run_eda(df, eda_options)

            if st.button("–û–±—É—á–∏—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"):
                st.info("\u23F3 –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

                model_name = selected_model
                if selected_model == "Logistic Regression (balanced)":
                    model_name = "Logistic Regression"

                model, metrics, models, X_test_scaled, y_test, y_pred, scaler = train_and_save_model(
                    X_train, X_test, y_train, y_test, model_name=model_name
                )

                st.success(f"\U0001F3AF –ú–æ–¥–µ–ª—å {selected_model} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")

                st.subheader("\U0001F4CC –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
                for k, v in metrics.items():
                    st.write(f"**{k}:** {v:.3f}")

                st.session_state.all_model_metrics[selected_model] = metrics
                visualize_model(models, X_test_scaled, y_test, scaler)

                st.subheader("\U0001F50D –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix)")
                cm = confusion_matrix(y_test, y_pred)
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
                ax.set_xlabel("Predicted")
                ax.set_ylabel("Actual")
                ax.set_title(f"Confusion Matrix: {selected_model}")
                st.pyplot(fig)

            if st.session_state.all_model_metrics:
                st.subheader("\U0001F4CA –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º")
                df_metrics = pd.DataFrame(st.session_state.all_model_metrics).T.reset_index().rename(columns={"index": "Model"})
                st.dataframe(df_metrics.style.format(precision=2))

                df_melted = df_metrics.melt(id_vars="Model", var_name="Metric", value_name="Score")
                plt.figure(figsize=(10, 5))
                sns.barplot(data=df_melted, x="Metric", y="Score", hue="Model")
                plt.title("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º")
                plt.ylim(0.5, 1.0)
                st.pyplot(plt.gcf())
    else:
        st.info("\u2B06 –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å –∫–æ–ª–æ–Ω–∫–æ–π `churn`)")

# ---------- TAB 2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ----------
with tab2:
    st.markdown("### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    predict_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ 'churn'", type=["csv", "xlsx"], key="predict")

    if predict_file:
        df_pred = pd.read_csv(predict_file) if predict_file.name.endswith(".csv") else pd.read_excel(predict_file)
        df_pred.columns = df_pred.columns.str.lower().str.strip()

        st.subheader("–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
        st.dataframe(df_pred.head())

        model_files = [f for f in os.listdir("models") if f.endswith(".pkl") and f != "scaler.pkl"]
        selected_pkl = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å (.pkl) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", model_files)

        if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
            model, scaler = load_model_and_scaler(selected_pkl)
            result = run_prediction(model, scaler, df_pred)

            st.success("\u2705 –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")
            st.dataframe(result)

            st.download_button(
                label="\U0001F4E5 –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                data=result.to_csv(index=False).encode("utf-8"),
                file_name="predictions.csv",
                mime="text/csv"
            )

# ---------- TAB 3: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ----------
with tab3:
    st.markdown("### üë• –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤")
    n_clusters = st.slider("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", 2, 10, 5)

    if uploaded:
        df = df.copy() if 'df' in locals() else None
        df.columns = df.columns.str.lower().str.strip()

        clustered_df = run_clustering(df, n_clusters=n_clusters)
        plot_churn_by_cluster(clustered_df)

        # plot_cluster_distributions –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        # –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤–Ω—É—Ç—Ä—å run_clustering()

        categorical, _ = get_feature_groups()
        plot_categorical_distributions(clustered_df, categorical)

        with st.expander("üìå –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"):
            run_hierarchical_clustering(df)
    else:
        st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—É—á–∞—é—â–∏–π —Ñ–∞–π–ª –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
